import pandas as pd
from pandas import DataFrame
import csv
import re
import string
from pyvi import ViTokenizer

#Ä‘á»c dá»¯ liá»‡u tá»« csv
train_data = pd.read_csv('data_first100.csv',sep=',',keep_default_na=False)
# stopword = pd.read_csv('stop_word.csv',sep=',',keep_default_na=False)

# chuyá»ƒn sang list Ä‘á»ƒ cÃ³ thá»ƒ thay Ä‘á»•i gÃ­a trá»‹
comment_var = list(train_data.comment)
# stopword_var = list(stopword.title)

#loáº¡i bá» cÃ¡c kÃ­ tá»± Ä‘áº·c biá»‡t, dáº¥u cÃ¢u
#khÃ´ng cáº§n remove khoáº£ng tráº¯ng, vÃ¬ khi dÃ¹ng CountVectorizer, sklearn k tÃ­nh khoáº£ng tráº¯ng
def remove_symbol(text):
     remove_list =[
                    #remove cÃ¡c biá»ƒu tÆ°á»£ng vÃ  kÃ­ tá»± xuá»‘ng dÃ²ng
                    'ğŸ‘¹', 'ğŸ‘»', 'ğŸ’ƒ','ğŸ¤™', 'ğŸ‘','ğŸ’„', 'ğŸ’', 'ğŸ’©','ğŸ˜•', 'ğŸ˜±',
                    'ğŸ˜¸','ğŸ˜¾', 'ğŸš«',  'ğŸ¤¬','ğŸ§š', 'ğŸ§¡','ğŸ¶','ğŸ‘', 'ğŸ˜£','âœ¨', 'â£','â˜€',
                    'â™¥', 'ğŸ¤©', 'ğŸ’Œ','ğŸ¤£', 'ğŸ–¤', 'ğŸ¤¤', ':(', 'ğŸ˜¢',
                    'â¤', 'ğŸ˜', 'ğŸ˜˜', 'ğŸ˜ª', 'ğŸ˜Š','?', 'ğŸ˜', 'ğŸ’–', 'ğŸ˜Ÿ', 'ğŸ˜­',
                    'ğŸ’¯', 'ğŸ’—', 'â™¡', 'ğŸ’œ', 'ğŸ¤—','^^', 'ğŸ˜¨', 'â˜º', 'ğŸ’‹', 'ğŸ‘Œ',
                    'ğŸ˜–', 'ğŸ˜€', ':((', 'ğŸ˜¡', 'ğŸ˜ ','ğŸ˜’', 'ğŸ™‚', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜„',
                    'ğŸ˜™', 'ğŸ˜¤', 'ğŸ˜', 'ğŸ˜†', 'ğŸ’š','âœŒ', 'ğŸ’•', 'ğŸ˜', 'ğŸ˜“', 'ï¸ğŸ†—ï¸',
                    'ğŸ˜‰', 'ğŸ˜‚', ':v', '=))', 'ğŸ˜‹','ğŸ’“', 'ğŸ˜', ':3', 'ğŸ˜«', 'ğŸ˜¥',
                    'ğŸ˜ƒ', 'ğŸ˜¬' ,' ğŸ˜¬ ', 'ğŸ˜Œ', ' ğŸ˜Œ ', 'ğŸ’›', 'ğŸ¤', 'ğŸˆ',
                    'ğŸ˜—', 'ğŸ¤”', 'ğŸ˜‘', 'ğŸ”¥', 'ğŸ™','ğŸ†—', 'ğŸ˜»', 'ğŸ’™', 'ğŸ’Ÿ',
                    'ğŸ˜š', 'âŒ', 'ğŸ‘', ';)', '<3','ğŸŒ',  'ğŸŒ·', 'ğŸŒ¸', 'ğŸŒº',
                    'ğŸŒ¼', 'ğŸ“', 'ğŸ…', 'ğŸ¾', 'ğŸ‘‰','ğŸ’', 'ğŸ’', 'ğŸ’¥', 'ğŸ’ª',
                    'ğŸ’°',  'ğŸ˜‡', 'ğŸ˜›', 'ğŸ˜œ','ğŸ™ƒ', 'ğŸ¤‘', 'ğŸ¤ª','â˜¹',  'ğŸ’€',
                    'ğŸ˜”', 'ğŸ˜§', 'ğŸ˜©', 'ğŸ˜°', 'ğŸ˜³','ğŸ˜µ', 'ğŸ˜¶', 'ğŸ™','ğŸ°','ğŸ¹','ğŸ¨','ğŸª','â˜•',
                    'ğŸŒ²','â›…','ğŸŒ','ğŸ‘','ğŸ','ğŸŒ»','ğŸ˜…', 'ğŸ»','ğŸ‰ï¸','\n']
     for k in remove_list:
          text = text.replace(k,' ')
     return text

#thay tháº¿ cÃ¡c tá»« viáº¿t táº¯t, viáº¿t sai, tiáº¿ng anh
def replace_word(text):
     replace_list = {
                    #cÃ¡c váº§n viáº¿t sai chÃ­nh táº£, cÃ¡c dáº¥u cÃ¢u viáº¿t báº±ng kÃ­ hiá»‡u
                    'Ã²a': 'oÃ ', 'Ã³a': 'oÃ¡', 'á»a': 'oáº£', 'Ãµa': 'oÃ£', 'á»a': 'oáº¡', 'Ã²e': 'oÃ¨',
                     'Ã³e': 'oÃ©','á»e': 'oáº»', 'Ãµe': 'oáº½', 'á»e': 'oáº¹', 'Ã¹y': 'uá»³', 'Ãºy': 'uÃ½',
                     'á»§y': 'uá»·', 'Å©y': 'uá»¹','á»¥y': 'uá»µ', 'uáº£': 'á»§a', 'aÌ‰': 'áº£', 'Ã´Ì': 'á»‘',
                     'uÂ´': 'Ãº','Ã´Ìƒ': 'á»—', 'Ã´Ì€': 'á»“', 'Ã´Ì‰': 'á»•', 'Ã¢Ì': 'áº¥', 'Ã¢Ìƒ': 'áº«',
                     'Ã¢Ì‰': 'áº©', 'Ã¢Ì€': 'áº§', 'oÌ‰': 'á»', 'Ãª`': 'á»','ÃªÌƒ': 'á»…', 'ÄƒÌ': 'áº¯', 
                     'uÌ‰': 'á»§', 'ÃªÌ': 'áº¿', 'Æ¡Ì‰': 'á»Ÿ', 'iÌ‰': 'á»‰', 'eÌ‰': 'áº»', 'Ã k': 'Ã ',
                     'ak`': 'Ã ','gÃ­a': 'giÃ¡', 
                     'a`': 'Ã ', 'iË‹': 'Ã¬', 'ÄƒÂ´': 'áº¯','Æ°Ì‰': 'á»­', 'eËœ': 'áº½', 'yËœ': 'á»¹',
                     'aÂ´': 'Ã¡', ' rÅ© ': ' rá»§ ',
                     #cÃ¡c tá»« Ä‘Æ°á»£c viáº¿t táº¯t
                     ' Ã¹i ':' rá»“i ', ' rÃ¹i ': ' rá»“i ', ' rÃ²i ': ' rá»“i ', ' roÃ i ':' rá»“i ', ' km ': ' khuyáº¿n mÃ£i ',
                     ' hnai': ' hÃ´m nay ', ' hnay': ' hÃ´m nay ', '0k ': ' giÃ¡ cáº£ ','1k ': ' giÃ¡ cáº£ ',
                     '2k ': ' giÃ¡ cáº£ ','3k ': ' giÃ¡ cáº£ ','4k ': ' giÃ¡ cáº£ ','5k ': ' giÃ¡ cáº£ ',
                     '6k ': ' giÃ¡ cáº£ ','7k ': ' giÃ¡ cáº£ ','8k ': ' giÃ¡ cáº£ ','9k ': ' giÃ¡ cáº£ ',
                     ' k ': ' khÃ´ng ', ' nv ': ' nhÃ¢n viÃªn ', ' cfe ': ' cafe ', ' cphe ': ' cafe ',
                     ' caphe ': ' cafe ', ' bt ': ' bÃ¬nh thÆ°á»ng ', ' ko ': ' khÃ´ng ',' Ä‘Ã´g uá»‘ng ':' Ä‘á»“ uá»‘ng ',
                     ' ae ': ' anh em ', ' ce ':' chá»‹ em ', ' ace ': ' anh chá»‹ em ', ' vs ': ' vá»›i ',
                     ' bt ': ' bÃ¬nh thÆ°á»ng ', ' nt ': ' nháº¯n tin ', ' mik ': ' mÃ¬nh ', ' cf ': ' cafe ',
                     ' nhÆ° v ': ' nhÆ° váº­y ',
                     #cÃ¡c tá»« tiáº¿ng anh
                     'boardgame': 'trÃ² chÆ¡i trÃªn bÃ n', 'dilivery': 'giao hÃ ng',
                     'fre': 'miá»…n phÃ­', 'free': 'miá»…n phÃ­', 'order': 'Ä‘áº·t hÃ ng',
                     'sandwich': 'bÃ¡nh mÃ¬', 'hamburger': 'bÃ¡nh mÃ¬', 'matcha': 'nÆ°á»›c uá»‘ng',
                     ' decor ': ' trang trÃ­ ', ' ok': ' á»•n ', ' take away': ' mang Ä‘i ', 'smothies': 'nÆ°á»›c uá»‘ng',
                     'americano': 'nÆ°á»›c uá»‘ng',  ' ice blended ': ' nÆ°á»›c uá»‘ng ', ' cokie cream ': ' nÆ°á»›c uá»‘ng ',   
                     ' milk tea ': ' nÆ°á»›c uá»‘ng ', ' cocktail': ' nÆ°á»›c uá»‘ng ', ' puding ': ' bÃ¡nh ', ' flan ': ' bÃ¡nh ',

                     }
     for k, v in replace_list.items():
          text = text.replace(k, v)
     return text

#loáº¡i bá» cÃ¡c dá»¯ liá»‡u khÃ´ng cÃ³ Ã½ nghÄ©a (khÃ´ng cÃ³ trong bá»™ stop word)
def remove_nonsense_word(text):
     remove_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
                    'hi hi', 'hÃ¬ hÃ¬', 'he he', 'ha ha', 'hÃª hÃª', 'hÃ¡ hÃ¡', 'há» há»', 'hÃ¨ hÃ¨',
                    'bÃ¬nh thÆ°á»ng'
                    ]
     for k in remove_list:
          text = text.replace(k,' ')
     return text

#loáº¡i bá» cÃ¡c khoáº£ng tráº¯ng dÆ° thá»«a
def remove_space_redundant(text):
     text = text.strip()
     text = re.sub(' +', ' ',text)
     return text


#loáº¡i bá» cÃ¡c stopword
def remove_stopword(text):
     for k in stopword_var:
          k = ' ' + k + ' '
          text = ' ' + text + ' '
          text = text.replace(k,' ')
     return text

#tiá»n xá»­ lÃ½ 1 chuá»—i dá»¯ liá»‡u
def string_preprocessing(text):
     #lowercase táº¥t cáº£ cÃ¡c string
     text = text.lower()   

     #loáº¡i bá» cÃ¡c symbol
     text = remove_symbol(text)

     #loáº¡i bá» cÃ¡c dáº¥u cÃ¢u
     translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))
     text = text.translate(translator)

     #loáº¡i bá» cÃ¡c kÃ­ tá»± kÃ©o dÃ i
     text = re.sub(r'([A-Z])\1+', lambda m: m.group(1).lower(), text, flags=re.IGNORECASE)  

     #thay tháº¿ cÃ¡c tá»« viáº¿t táº¯t, sai chÃ­nh táº£
     text = replace_word(text)

     #loáº¡i bá» cÃ¡c dá»¯ liá»‡u dÆ° thá»«a sau khi Ä‘Ã£ replace
     text = remove_nonsense_word(text)

     #bá» cÃ¡c khoáº£ng space thá»«a 
     # text = remove_space_redundant(text)

     #loáº¡i bá» stopword dÃ¹ng bá»™ tá»« Ä‘iá»ƒn stopword 
     # text= remove_stopword(text)

     #tÃ¡ch tá»« dÃ¹ng bá»™ tá»« tiáº¿ng viá»‡t cá»§a pyvi 
     text = ViTokenizer.tokenize(text)

     return text

#xá»­ lÃ½ list dá»¯ liá»‡u
def data_preprocessing(list_data):
     length = len(list_data)
     for i in range(length):
          list_data[i] = string_preprocessing(list_data[i])
     return list_data

#xuáº¥t dá»¯ liá»‡u ra csv file theo tá»«ng cá»™t
id_var = list(train_data.id)
comment_var1 = data_preprocessing(comment_var)
food_var = list(train_data.food)
drink_var = list(train_data.drink)
price_var = list(train_data.price)
staff_var = list(train_data.staff)
service_var = list(train_data.service)
space_var = list(train_data.space)
hygiene_var = list(train_data.hygiene)

Cars = {'id': id_var,
        'comment': comment_var1,
        'food': food_var,
        'drink': drink_var,
        'price': price_var,
        'staff': staff_var,
        'service': service_var,
        'space': space_var,
        'hygiene': hygiene_var,
        }

df = DataFrame(Cars, columns= ['id', 'comment','food','drink','price','staff','service','space','hygiene'])
export_csv = df.to_csv ('data.csv', index = None, header=True)


########test
# print(data_preprocessing(comment_var))

